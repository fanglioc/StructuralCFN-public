@article{chen2016xgboost,
  title={XGBoost: A Scalable Tree Boosting System},
  author={Chen, Tianqi and Guestrin, Carlos},
  journal={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year={2016}
}

@article{arik2021tabnet,
  title={TabNet: Attentive Interpretable Tabular Learning},
  author={Arik, Sercan {\"O}. and Pfister, Tomas},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2021}
}

@article{gorishniy2021revisiting,
  title={Revisiting Deep Learning Models for Tabular Data},
  author={Gorishniy, Yury and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{li2025cfn,
  title={Compositional Function Networks: A High-Performance Alternative to Deep Neural Networks with Built-in Interpretability},
  author={Li, Fang},
  journal={arXiv preprint arXiv:2507.21004},
  year={2025}
}

@article{hastie1986gam,
  title={Generalized Additive Models},
  author={Hastie, Trevor and Tibshirani, Robert},
  journal={Statistical Science},
  volume={1},
  number={3},
  pages={297--318},
  year={1986}
}

@article{nori2019ebm,
  title={InterpretML: A Unified Framework for Machine Learning Interpretability},
  author={Nori, Harsha and Jenkins, Samuel and Koch, Paul and Caruana, Rich},
  journal={arXiv preprint arXiv:1909.09223},
  year={2019}
}

@article{popov2020node,
  title={Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data},
  author={Popov, Sergei and Morozov, Stanislav and Babenko, Artem},
  journal={International Conference on Learning Representations},
  year={2020}
}

@article{somepalli2021saint,
  title={SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training},
  author={Somepalli, Gowthami and Goldblum, Micah and Schwarzschild, Avi and Bruss, C. Bayan and Goldstein, Tom},
  journal={arXiv preprint arXiv:2106.01342},
  year={2021}
}

@article{agarwal2021nam,
  title={Neural Additive Models: Interpretable Machine Learning with Neural Nets},
  author={Agarwal, Rishabh and Melnick, Levi and Frosst, Nicholas and Zhang, Xuezhou and Lengerich, Benjamin James and Caruana, Rich and Hinton, Geoffrey E.},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{jeffares2023gandalf,
  title={GANDALF: Gated Adaptive Network for Deep Automated Learning of Features},
  author={Jeffares, Luke and Liu, Tian and Crabb{\'e}, Jonathan and Imrie, Fergus and van der Schaar, Mihaela},
  journal={International Conference on Machine Learning},
  year={2023}
}

@article{hollmann2023tabpfn,
  title={TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second},
  author={Hollmann, Noah and M{\"u}ller, Samuel and Eggensperger, Katharina and Hutter, Frank},
  journal={International Conference on Learning Representations},
  year={2023}
}

@article{lundberg2017unified,
  title={A Unified Approach to Interpreting Model Predictions},
  author={Lundberg, Scott M. and Lee, Su-In},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{rumelhart1986mlp,
  title={Learning Representations by Back-Propagating Errors},
  author={Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  journal={Nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986}
}

@inproceedings{mundhenk2021dso,
  title={Symbolic Regression via Deep Reinforcement Learning Combined with a Unified Error Metric},
  author={Mundhenk, T. Nathan and Landgrebe, Daniel and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}